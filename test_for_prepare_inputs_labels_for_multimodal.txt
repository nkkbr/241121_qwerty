You are using a model of type qwen2 to instantiate a model of type qwerty_qwen2. This is not supported for all configurations of models and can yield errors.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:03,  1.10s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]
Some weights of QwertyQwen2ForCausalLM were not initialized from the model checkpoint at Qwen/Qwen2.5-7B-Instruct and are newly initialized: ['model.mm_projector.0.bias', 'model.mm_projector.0.weight', 'model.mm_projector.2.bias', 'model.mm_projector.2.weight', 'model.vision_model.vision_model.embeddings.class_embedding', 'model.vision_model.vision_model.embeddings.patch_embedding.weight', 'model.vision_model.vision_model.embeddings.position_embedding.weight', 'model.vision_model.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_model.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_model.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_model.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_model.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_model.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_model.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_model.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_model.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_model.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_model.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_model.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_model.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_model.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_model.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_model.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_model.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_model.vision_model.post_layernorm.bias', 'model.vision_model.vision_model.post_layernorm.weight', 'model.vision_model.vision_model.pre_layrnorm.bias', 'model.vision_model.vision_model.pre_layrnorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
=======================================================================================================
input_ids
tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,
         151645,    198, 151644,    872,    198, 151665,    198,   7985,    264,
          50537,    714,  38219,  12126,    315,    279,   6802,     13, 151645,
            198, 151644,  77091,    198,  38293,    279,   4479,  19059,    504,
            279,   9500,    311,    279,   7055,   2685, 151645, 151643, 151643,
         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,
         151643, 151643, 151643, 151643],
        [151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,
         151645,    198, 151644,    872,    198, 151665,    198,  21195,    264,
          16830,   4008,    315,    279,   6548,    594,   1376,   4419,     13,
         151645,    198, 151644,  77091,    198,    275,    572,   5798,    369,
          10826,    311,  12449,    279,  80692,    287,   8628,   3403,    481,
           1380,  19879,   5545,    264,  54844,  12348,    481,  41566,   1154,
            264,   8640,  13829, 151645],
        [151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,
         151645,    198, 151644,    872,    198, 151665,    198,   4021,    264,
          16830,  19221,  14064,    279,   2168,  10449,     13, 151645,    198,
         151644,  77091,    198,    896,   2603,   6946,  61164,    678,    916,
            279,   1909,    315,   6946,    943,    659, 151645, 151643, 151643,
         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,
         151643, 151643, 151643, 151643],
        [151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,
         151645,    198, 151644,    872,    198, 151665,    198,   4021,    264,
          16830,  19221,  14064,    279,   2168,  10449,     13, 151645,    198,
         151644,  77091,    198,     75,  17054,    498,   1184,    264,   1293,
          22875,    311,    728,    916,    697,   1182,   2929,   1154,   1181,
           2238,   9255,    311,    387,   3330,  18838,    448,   1846,   2632,
          55637,    389,    659, 151645]])

attention_mask
tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True]])

labels
tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,  38293,    279,   4479,  19059,    504,
            279,   9500,    311,    279,   7055,   2685, 151645,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,    275,    572,   5798,    369,
          10826,    311,  12449,    279,  80692,    287,   8628,   3403,    481,
           1380,  19879,   5545,    264,  54844,  12348,    481,  41566,   1154,
            264,   8640,  13829, 151645],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,    896,   2603,   6946,  61164,    678,    916,
            279,   1909,    315,   6946,    943,    659, 151645,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,     75,  17054,    498,   1184,    264,   1293,
          22875,    311,    728,    916,    697,   1182,   2929,   1154,   1181,
           2238,   9255,    311,    387,   3330,  18838,    448,   1846,   2632,
          55637,    389,    659, 151645]])

=======================================================================================================
new_position_ids:
tensor([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,
         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,
         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,
         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,
         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,
         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,
         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,
         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,
         616, 617, 618,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,
         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,
         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,
         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,
         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,
         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,
         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,
         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,
         616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,
         630, 631, 632, 633],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,
         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,
         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,
         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,
         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,
         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,
         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,
         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,
         616, 617, 618,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
           0,   0,   0,   0],
        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,
          14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,
          28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,
          42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,
          56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,
          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,
          84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,
          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,
         112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,
         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,
         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,
         154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,
         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,
         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,
         196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,
         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,
         224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,
         238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,
         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,
         266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,
         280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,
         294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,
         308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,
         322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,
         336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,
         350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,
         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,
         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,
         392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,
         406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,
         420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,
         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,
         448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,
         462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,
         476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,
         490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,
         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517,
         518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531,
         532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,
         546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,
         560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,
         574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587,
         588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,
         602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615,
         616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629,
         630, 631, 632, 633]])

new_attention_mask:
tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False],
        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
          True,  True,  True,  True]])

new_labels
tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,  38293,    279,   4479,  19059,    504,
            279,   9500,    311,    279,   7055,   2685, 151645,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,    275,    572,   5798,    369,
          10826,    311,  12449,    279,  80692,    287,   8628,   3403,    481,
           1380,  19879,   5545,    264,  54844,  12348,    481,  41566,   1154,
            264,   8640,  13829, 151645],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,    896,   2603,   6946,  61164,    678,    916,
            279,   1909,    315,   6946,    943,    659, 151645,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100],
        [  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,
           -100,   -100,   -100,     75,  17054,    498,   1184,    264,   1293,
          22875,    311,    728,    916,    697,   1182,   2929,   1154,   1181,
           2238,   9255,    311,    387,   3330,  18838,    448,   1846,   2632,
          55637,    389,    659, 151645]])

new_inputs_embeds.shape
torch.Size([4, 634, 3584])
