
  0%|                                                                                                                                                                                                 | 0/4651 [00:00<?, ?it/s]
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
  0%|                                                                                                                                                                                                 | 0/4651 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/data/uchiha_ssd2/fengqi/241121_qwerty/train.py", line 325, in <module>
  File "/data/uchiha_ssd2/fengqi/241121_qwerty/train.py", line 316, in train
    # 保存训练状态与权重，保存修改过的分词器
    ^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 2122, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 2474, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 3572, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 3625, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 820, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 808, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 863, in forward
    output = self._fsdp_wrapped_module(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 820, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 808, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/data/uchiha_ssd2/fengqi/241121_qwerty/qwerty_qwen2.py", line 69, in forward
    ) = self.prepare_inputs_labels_for_multimodal(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/uchiha_ssd2/fengqi/241121_qwerty/qwerty_qwen2.py", line 142, in prepare_inputs_labels_for_multimodal
    image_features = self.vision_model(images,output_hidden_states=True).hidden_states[-2]   # 选取了倒数第二层，形状是(batch_size, 577, 1024) 577是一个CLS + (336/14)**2。 也可以不选CLS，只使用(batch_size, 576, 1024)
                     ^^^^^^^^^^^^^^^^^
  File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1729, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'QwertyQwen2ForCausalLM' object has no attribute 'vision_model'
[rank0]: Traceback (most recent call last):
[rank0]:   File "/data/uchiha_ssd2/fengqi/241121_qwerty/train.py", line 325, in <module>
[rank0]:   File "/data/uchiha_ssd2/fengqi/241121_qwerty/train.py", line 316, in train
[rank0]:     # 保存训练状态与权重，保存修改过的分词器
[rank0]:     ^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 2122, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 2474, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 3572, in training_step
[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/transformers/trainer.py", line 3625, in compute_loss
[rank0]:     outputs = model(**inputs)
[rank0]:               ^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 820, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 808, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py", line 863, in forward
[rank0]:     output = self._fsdp_wrapped_module(*args, **kwargs)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 820, in forward
[rank0]:     return model_forward(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/accelerate/utils/operations.py", line 808, in __call__
[rank0]:     return convert_to_fp32(self.model_forward(*args, **kwargs))
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/amp/autocast_mode.py", line 43, in decorate_autocast
[rank0]:     return func(*args, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/uchiha_ssd2/fengqi/241121_qwerty/qwerty_qwen2.py", line 69, in forward
[rank0]:     ) = self.prepare_inputs_labels_for_multimodal(
[rank0]:         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/uchiha_ssd2/fengqi/241121_qwerty/qwerty_qwen2.py", line 142, in prepare_inputs_labels_for_multimodal
[rank0]:     image_features = self.vision_model(images,output_hidden_states=True).hidden_states[-2]   # 选取了倒数第二层，形状是(batch_size, 577, 1024) 577是一个CLS + (336/14)**2。 也可以不选CLS，只使用(batch_size, 576, 1024)
[rank0]:                      ^^^^^^^^^^^^^^^^^
[rank0]:   File "/data/satori_hdd4/fengqi/anaconda3/envs/base_3_12/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1729, in __getattr__
[rank0]:     raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
[rank0]: AttributeError: 'QwertyQwen2ForCausalLM' object has no attribute 'vision_model'
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])
dict_keys(['input_ids', 'labels', 'images'])